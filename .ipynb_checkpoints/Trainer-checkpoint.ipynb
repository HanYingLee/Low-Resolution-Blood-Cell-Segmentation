{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859291b7-dcdf-4a14-9072-254149152728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "import numpy as np\n",
    "from MobileSR import MobileSR\n",
    "\n",
    "class SuperResolutionDataset(Dataset):\n",
    "    def __init__(self, hr_dir, lr_dir, transform=None):\n",
    "        self.hr_dir = hr_dir\n",
    "        self.lr_dir = lr_dir\n",
    "        self.transform = transform\n",
    "        self.hr_images = sorted(os.listdir(hr_dir))\n",
    "        self.lr_images = sorted(os.listdir(lr_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hr_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hr_image_path = os.path.join(self.hr_dir, self.hr_images[idx])\n",
    "        lr_image_path = os.path.join(self.lr_dir, self.lr_images[idx])\n",
    "\n",
    "        hr_image = Image.open(hr_image_path).convert(\"RGB\")\n",
    "        lr_image = Image.open(lr_image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            hr_image = self.transform(hr_image)\n",
    "            lr_image = self.transform(lr_image)\n",
    "\n",
    "        return lr_image, hr_image\n",
    "\n",
    "\n",
    "def compute_psnr(outputs, hr_images):\n",
    "    \"\"\"Compute the PSNR for the outputs and ground truth high-resolution images.\"\"\"\n",
    "    outputs_np = outputs.cpu().detach().numpy()\n",
    "    hr_images_np = hr_images.cpu().detach().numpy()\n",
    "    psnr = peak_signal_noise_ratio(hr_images_np, outputs_np, data_range=255.0)\n",
    "    return psnr\n",
    "\n",
    "\n",
    "# Validation function\n",
    "def validate_one_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_psnr = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for lr_images, hr_images in tqdm(dataloader, desc=\"Validation\"):\n",
    "            lr_images, hr_images = lr_images.to(device), hr_images.to(device)\n",
    "            outputs = model(lr_images)\n",
    "            loss = criterion(outputs, hr_images)\n",
    "            val_loss += loss.item()\n",
    "            val_psnr += compute_psnr(outputs, hr_images)\n",
    "\n",
    "    avg_loss = val_loss / len(dataloader)\n",
    "    avg_psnr = val_psnr / len(dataloader)\n",
    "    return avg_loss, avg_psnr\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_psnr = 0\n",
    "\n",
    "    for lr_images, hr_images in tqdm(dataloader, desc=\"Training\"):\n",
    "        lr_images, hr_images = lr_images.to(device), hr_images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(lr_images)\n",
    "        loss = criterion(outputs, hr_images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_psnr += compute_psnr(outputs, hr_images)\n",
    "\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    avg_psnr = epoch_psnr / len(dataloader)\n",
    "    return avg_loss, avg_psnr\n",
    "\n",
    "\n",
    "# Training and validation loop\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, save_folder, device):\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        # Train\n",
    "        train_loss, train_psnr = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train PSNR: {train_psnr:.2f}\")\n",
    "\n",
    "        # Validate\n",
    "        val_loss, val_psnr = validate_one_epoch(model, val_loader, criterion, device)\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val PSNR: {val_psnr:.2f}\")\n",
    "\n",
    "        # Step Scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # Save Model Checkpoint\n",
    "        checkpoint_path = os.path.join(save_folder, f\"model_epoch_{epoch + 1}.pth\")\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved model checkpoint to {checkpoint_path}\")\n",
    "\n",
    "\n",
    "# Define augmentation pipelines\n",
    "transform_train_aug1 = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "transform_train_aug2 = transforms.Compose([\n",
    "    transforms.RandomVerticalFlip(p=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "transform_train_aug3 = transforms.Compose([\n",
    "    transforms.RandomRotation(90),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Validation transform (no augmentation)\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create datasets with different augmentation pipelines\n",
    "train_dataset1 = SuperResolutionDataset(\n",
    "    hr_dir=\"../BCCD_mask/ssr_small/train_HR\",\n",
    "    lr_dir=\"../BCCD_mask/ssr_small/train_LR_bicubic/X4\",\n",
    "    transform=transform_train_aug1,\n",
    ")\n",
    "\n",
    "train_dataset2 = SuperResolutionDataset(\n",
    "    hr_dir=\"../BCCD_mask/ssr_small/train_HR\",\n",
    "    lr_dir=\"../BCCD_mask/ssr_small/train_LR_bicubic/X4\",\n",
    "    transform=transform_train_aug2,\n",
    ")\n",
    "\n",
    "train_dataset3 = SuperResolutionDataset(\n",
    "    hr_dir=\"../BCCD_mask/ssr_small/train_HR\",\n",
    "    lr_dir=\"../BCCD_mask/ssr_small/train_LR_bicubic/X4\",\n",
    "    transform=transform_train_aug3,\n",
    ")\n",
    "\n",
    "# Combine training datasets into one\n",
    "combined_train_dataset = ConcatDataset([train_dataset1, train_dataset2, train_dataset3])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(combined_train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "val_dataset = SuperResolutionDataset(\n",
    "    hr_dir=\"../BCCD_mask/ssr_small/val_HR\",\n",
    "    lr_dir=\"../BCCD_mask/ssr_small/val_LR_bicubic/X4\",\n",
    "    transform=transform_val,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Model, optimizer, and training configuration\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Training configuration\n",
    "model = MobileSR(n_feats=40, n_heads=8, ratios=[4, 2, 2, 2, 4], upscaling_factor=4).to(device)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=200000, gamma=0.5)\n",
    "\n",
    "# Train and validate the model\n",
    "save_folder = \"20epochs_combineddataset_nopretrain_Normalization\"\n",
    "train_and_validate(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=100, save_folder=save_folder, device=device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
